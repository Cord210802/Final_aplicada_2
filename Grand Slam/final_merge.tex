% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{longtable}
\KOMAoption{captions}{tableheading}
\makeatletter
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Estad√≠stica Aplicada II - Trabajo final},
  pdfauthor={Juan Pablo Cordero Mayorga; Jaime Fernando Uria Medina; Gerardo Armando Guerrero √Ålvarez},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Estad√≠stica Aplicada II - Trabajo final}
\author{Juan Pablo Cordero Mayorga \and Jaime Fernando Uria
Medina \and Gerardo Armando Guerrero √Ålvarez}
\date{}

\begin{document}
\maketitle
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[boxrule=0pt, interior hidden, borderline west={3pt}{0pt}{shadecolor}, frame hidden, breakable, sharp corners, enhanced]}{\end{tcolorbox}}\fi

Los torneos de Grand Slam no solo concentran el talento m√°s alto del
tenis profesional, sino que tambi√©n implican una compleja log√≠stica con
cientos de partidos, m√∫ltiples sedes y contratos televisivos que superan
los 300 millones de d√≥lares por edici√≥n. En ese contexto, anticipar con
precisi√≥n la duraci√≥n de cada encuentro es importante para organizar
horarios de cancha, optimizar la parrilla de transmisiones y planear la
recuperaci√≥n de los jugadores.

Este estudio se propone modelar y predecir la duraci√≥n de los partidos
masculinos disputados entre 1991 y 2022, comparando tres enfoques
metodol√≥gicos: regresi√≥n lineal (OLS), modelos de √°rboles (Random Forest
y XGBoost) y modelos lineales generalizados Gamma con enlace
logar√≠tmico.

Se construyeron cuatro versiones para cada tipo de modelo, incorporando
progresivamente nuevas variables para evaluar la mejora en cada
iteraci√≥n.

La regresi√≥n lineal OLS mostr√≥ una mejora modesta al incluir m√°s
variables, alcanzando su mejor resultado con un RMSE de 44.80 minutos y
un R¬≤ de 0.055 en el conjunto de prueba.

Este desempe√±o fue superado por los modelos de √°rboles, especialmente
XGBoost, cuyo modelo completo logr√≥ reducir el RMSE a 44.81 minutos,
aunque con signos claros de sobreajuste. Por su parte, el modelo Gamma
destac√≥ por su equilibrio entre precisi√≥n (RMSE: 44.98) y robustez
(pseudo R¬≤: 0.0574), siendo menos sensible al overfitting que los
m√©todos de machine learning.

Las variables con mayor poder explicativo fueron la superficie de juego
(particularmente el pasto, que reduce significativamente la duraci√≥n),
la diferencia de puntos en el ranking y el promedio de minutos jugados
por los tenistas. Se validaron los supuestos de independencia en los
modelos lineales y se aplic√≥ un an√°lisis de multicolinealidad para
eliminar variables redundantes (VIF \textgreater{} 10). Aunque los
modelos no incorporan factores como clima o lesiones, los resultados
sugieren que es factible predecir la duraci√≥n de los partidos con una
precisi√≥n √∫til para aplicaciones operativas y comerciales en torneos de
gran escala.

\hypertarget{feature-engineering}{%
\subsection{Feature engineering}\label{feature-engineering}}

Para mejorar la capacidad predictiva de los modelos, se implement√≥ un
proceso sistem√°tico de ingenier√≠a de variables enfocado exclusivamente
en partidos masculinos a cinco sets disputados en torneos de Grand Slam.
Primero, se reetiquetaron los jugadores como \emph{jugador\_1} y
\emph{jugador\_2} en funci√≥n de sus puntos de ranking previos al
partido, con el fin de garantizar consistencia en las estad√≠sticas
asociadas a cada rol. Luego, se crearon variables derivadas como la
diferencia de ranking (\texttt{rank\_diff}), edad (\texttt{age\_diff}) y
la cercan√≠a competitiva (\texttt{close\_ranking}), buscando capturar
relaciones no lineales entre caracter√≠sticas individuales y duraci√≥n del
partido.

Posteriormente, se reformate√≥ el dataset a un esquema centrado en el
jugador para calcular promedios m√≥viles de rendimiento ---como aces,
doble faltas, puntos ganados al servicio y duraci√≥n de partidos---
usando una ventana retrospectiva de cinco encuentros. Estas m√©tricas
fueron luego reagrupadas nuevamente a nivel de partido, distinguiendo
entre el historial del \texttt{jugador\_1} y del \texttt{jugador\_2}.
Este enfoque permiti√≥ incorporar conocimiento hist√≥rico del desempe√±o
individual sin incurrir en \emph{data leakage}, ya que toda informaci√≥n
se construy√≥ exclusivamente con partidos previos al observado.
Finalmente, se eliminaron las estad√≠sticas dentro del partido actual,
as√≠ como identificadores y columnas textuales irrelevantes, asegurando
que las variables finales fueran num√©ricas, informativas y compatibles
con el entrenamiento de modelos supervisados.

\hypertarget{feature-selection}{%
\subsection{Feature selection}\label{feature-selection}}

Una vez concluido el proceso de ingenier√≠a de variables, se procedi√≥ a
reducir dimensionalidad y eliminar redundancias mediante un an√°lisis
estad√≠stico formal. Dado que muchas de las m√©tricas generadas estaban
correlacionadas entre s√≠ ---por ejemplo, estad√≠sticas agregadas como
\texttt{jugador\_1\_1stWon} o \texttt{avg\_rank}---, era fundamental
mitigar la multicolinealidad, especialmente para preservar la
estabilidad de los modelos lineales y facilitar la interpretaci√≥n de los
coeficientes.

El criterio principal utilizado fue el Factor de Inflaci√≥n de la
Varianza (VIF), que mide cu√°nta varianza de una variable es explicada
por el resto. Se calcularon los VIF √∫nicamente para variables num√©ricas,
y se eliminaron aquellas cuyo VIF superaba el umbral de 10, un valor
est√°ndar que indica colinealidad severa. Este an√°lisis permiti√≥
conservar √∫nicamente aquellas variables con contribuci√≥n informativa no
redundante, reduciendo el riesgo de sobreajuste y asegurando un conjunto
parsimonioso para el modelado.

Como resultado de este filtrado, el conjunto final de variables
utilizadas en los modelos se compuso √∫nicamente por aquellas con bajo
VIF y con relevancia te√≥rica o emp√≠rica validada en etapas posteriores
del an√°lisis. Este conjunto form√≥ la base del modelo completo
(\emph{full model}) utilizado en las tres familias de modelos
predictivos.

\hypertarget{etl}{%
\subsection{ETL}\label{etl}}

Realizamos un proceso de Extracci√≥n, Transformaci√≥n y Carga (ETL) para
preparar los datos de los partidos masculinos de Grand Slam entre 1991 y
2022. La extracci√≥n se llev√≥ a cabo desde la base de datos de la ATP,
que contiene informaci√≥n detallada sobre cada partido, incluyendo
estad√≠sticas individuales y del encuentro. Posteriormente, se
transformaron los datos para unificar formatos, eliminar duplicados y
corregir inconsistencias. Finalmente, los datos fueron cargados en un
entorno adecuado para el an√°lisis, asegurando que todas las variables
estuvieran correctamente tipificadas y listas para su uso en modelos
predictivos.

\includegraphics{final_merge_files/figure-pdf/cell-4-output-1.png}

\includegraphics{final_merge_files/figure-pdf/cell-4-output-2.png}

\includegraphics{final_merge_files/figure-pdf/cell-4-output-3.png}

\includegraphics{final_merge_files/figure-pdf/cell-4-output-4.png}

\includegraphics{final_merge_files/figure-pdf/cell-4-output-5.png}

\begin{verbatim}

üìä VIF Scores (Numerical Features Only):
       feature  VIF
13     avg_age  inf
2   winner_age  inf
4    loser_age  inf
...
      feature       VIF
1   winner_ht  1.364780
3    loser_ht  1.331076
12   age_diff  1.041457

‚ùå Dropping high VIF features

‚ú® Tennis data analysis pipeline complete!
Final dataset shape: (10746, 18)
\end{verbatim}

\begin{longtable}[]{@{}llllllll@{}}
\toprule\noalign{}
& p1\_ht & p2\_ht & p1\_rank\_points & ... & round\_group\_QF &
round\_group\_SF & minutes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & 188.0 & 170.0 & 3889.0 & ... & 1.0 & 0.0 & 88.0 \\
1 & 188.0 & 180.0 & 2541.0 & ... & 1.0 & 0.0 & 147.0 \\
2 & 183.0 & 178.0 & 303.0 & ... & 1.0 & 0.0 & 204.0 \\
3 & 190.0 & 190.0 & 3528.0 & ... & 1.0 & 0.0 & 111.0 \\
4 & 188.0 & 188.0 & 2541.0 & ... & 0.0 & 1.0 & 242.0 \\
\end{longtable}

\hypertarget{regresiuxf3n-lineal}{%
\section{Regresi√≥n Lineal}\label{regresiuxf3n-lineal}}

\hypertarget{marco-teuxf3rico}{%
\subsection{Marco Te√≥rico}\label{marco-teuxf3rico}}

La regresi√≥n lineal constituye un modelo param√©trico fundamental en
estad√≠stica para analizar la relaci√≥n entre una variable dependiente
continua y un conjunto de variables independientes. Este modelo asume
una relaci√≥n lineal expresada mediante la ecuaci√≥n
\[y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip} + \varepsilon_i\]
donde los par√°metros \(\beta_0, \dots, \beta_p\) son estimados a trav√©s
del m√©todo de m√≠nimos cuadrados ordinarios (OLS), que minimiza la suma
de residuos al cuadrado.

El modelo mantiene su consistencia y eficiencia bajo los supuestos
cl√°sicos de linealidad en los par√°metros, independencia de errores,
homocedasticidad, ausencia de colinealidad perfecta y normalidad de los
errores en contextos inferenciales.

\includegraphics{final_merge_files/figure-pdf/cell-8-output-1.png}

\includegraphics{final_merge_files/figure-pdf/cell-8-output-2.png}

\includegraphics{final_merge_files/figure-pdf/cell-8-output-3.png}

\includegraphics{final_merge_files/figure-pdf/cell-8-output-4.png}

\includegraphics{final_merge_files/figure-pdf/cell-8-output-5.png}

\hypertarget{anuxe1lisis-de-resultados}{%
\subsubsection{An√°lisis de Resultados}\label{anuxe1lisis-de-resultados}}

En el presente estudio se implementaron cuatro configuraciones
progresivas del modelo OLS para evaluar la capacidad predictiva en la
duraci√≥n de partidos de tenis. El modelo 1 incorpora variables b√°sicas
como superficie del torneo, etapa del torneo y puntos de ranking de los
jugadores. El modelo 2 a√±ade estad√≠sticas de desempe√±o promedio
incluyendo aces y dobles faltas. El modelo 3 integra la duraci√≥n
promedio hist√≥rica de partidos por jugador, mientras que el modelo 4
representa la configuraci√≥n completa con todas las variables
seleccionadas tras el an√°lisis de multicolinealidad. Los resultados
revelan que todos los modelos presentan valores de considerablemente
bajos, con el modelo m√°s completo explicando √∫nicamente el 5.5\% de la
varianza en el conjunto de prueba, indicando una capacidad explicativa
limitada pero con mejoras progresivas en las m√©tricas de error conforme
se incorporan variables adicionales.

\hypertarget{resultados-de-desempeuxf1o-predictivo}{%
\paragraph{Resultados de Desempe√±o
Predictivo}\label{resultados-de-desempeuxf1o-predictivo}}

\begin{longtable}[]{@{}llllllll@{}}
\toprule\noalign{}
& Modelo & R¬≤\_train & R¬≤\_test & RMSE\_train & RMSE\_test & MAE\_train
& MAE\_test \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & 1 & 0.2035 & 0.0121 & 41.34 & 45.80 & 33.28 & 37.05 \\
1 & 2 & 0.3361 & 0.0197 & 37.74 & 45.63 & 30.14 & 36.86 \\
2 & 3 & 0.3363 & 0.0276 & 37.74 & 45.44 & 30.22 & 36.73 \\
3 & 4 & 0.3977 & 0.0289 & 35.95 & 45.41 & 28.66 & 36.71 \\
\end{longtable}

\hypertarget{coeficientes-muxe1s-relevantes-e-interpretaciuxf3n}{%
\paragraph{Coeficientes M√°s Relevantes e
Interpretaci√≥n}\label{coeficientes-muxe1s-relevantes-e-interpretaciuxf3n}}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
& Variable & Coeficiente & Interpretacion \\
Modelo & & & \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Modelo 1 & surface\_Grass & -9.13 & Los partidos en pasto duran 9.13 min
menos \\
Modelo 1 & surface\_Hard & -2.31 & La superficie dura reduce la duraci√≥n
en 2.31 min \\
Modelo 1 & round\_group\_SF & 0.90 & Las semifinales incrementan la
duraci√≥n en 0.90 min \\
Modelo 2 & round\_group\_SF & 1.36 & Aumento mayor al incorporar
estad√≠sticas de jugador \\
Modelo 2 & surface\_Grass & -9.12 & Se mantiene el efecto de
superficie \\
Modelo 3 & round\_group\_SF & 2.17 & Aumenta al incluir minutos
hist√≥ricos \\
Modelo 3 & surface\_Grass & -8.59 & Efecto consistente de reducci√≥n \\
Modelo 4 & surface\_Grass & -8.41 & Superficie sigue siendo el factor
m√°s influyente \\
Modelo 4 & round\_group\_SF & 2.61 & Aumenta la duraci√≥n respecto a
rondas anteriores \\
Modelo 4 & round\_group\_Other & -1.66 & Rondas iniciales tienen menor
duraci√≥n \\
\end{longtable}

El an√°lisis emp√≠rico demuestra que la regresi√≥n lineal, aun en su
configuraci√≥n m√°s comprehensiva, mantiene una capacidad explicativa
limitada coherente con la naturaleza multifactorial para modelar la
duraci√≥n de partidos de tenis, donde influyen variables no observadas
como estilos de juego, condiciones clim√°ticas y eventos fortuitos.

No obstante, el examen de coeficientes revela patrones sistem√°ticamente
significativos, particularmente el efecto de la superficie de juego,
donde los partidos en c√©sped presentan duraciones considerablemente
menores, consistente con la din√°mica de menor intercambio caracter√≠stica
de esta superficie. Las semifinales y finales exhiben incrementos
sostenidos en duraci√≥n, atribuibles a la mayor paridad competitiva en
etapas decisivas. Metodol√≥gicamente, la regresi√≥n lineal demuestra
utilidad como modelo base proporcionando transparencia interpretativa y
evaluaci√≥n de relaciones marginales entre variables, estableciendo un
\emph{benchmark} fundamental para la validaci√≥n de modelos no lineales
m√°s complejos, a pesar de su desempe√±o predictivo limitado.

\hypertarget{xg-boost}{%
\section{XG Boost}\label{xg-boost}}

\hypertarget{marco-teuxf3rico-1}{%
\subsection{Marco Te√≥rico}\label{marco-teuxf3rico-1}}

XGBoost (eXtreme Gradient Boosting) es un algoritmo de aprendizaje
supervisado basado en el principio de \emph{gradient boosting}, dise√±ado
para maximizar tanto la precisi√≥n predictiva como la eficiencia
computacional. A diferencia de los modelos param√©tricos cl√°sicos,
XGBoost construye de manera aditiva un conjunto (ensamble) de √°rboles de
decisi√≥n, de forma que cada nuevo √°rbol corrige los errores residuales
cometidos por el conjunto previo. Formalmente, la predicci√≥n para la
observaci√≥n \(i\) en la iteraci√≥n \(m\) se expresa como

\[
\hat{y}_i^{(m)} = \sum_{k=1}^m f_k(x_i)\,,
\]

donde cada \(f_k\) es un √°rbol de decisi√≥n que mapea el vector de
caracter√≠sticas \(x_i\) a un valor real. El objetivo es minimizar una
funci√≥n de p√©rdida penalizada sobre todo el ensamble:

\[
\mathcal{L} = \sum_{i=1}^n \ell\bigl(y_i,\hat{y}_i^{(m)}\bigr) \;+\; \sum_{k=1}^m \Omega(f_k)\,.
\]

Aqu√≠, \(\ell\) es una medida de error y \(\Omega(f)\) es un t√©rmino de
regularizaci√≥n que controla la complejidad de cada √°rbol:

\[
\Omega(f) = \gamma T + \tfrac{1}{2} \lambda \sum_{j=1}^T w_j^2,
\]

donde \(T\) es el n√∫mero de hojas del √°rbol y \(w_j\) el valor de
predicci√≥n en la hoja \(j\). Los hiperpar√°metros \(\gamma\) y
\(\lambda\) permiten penalizar tanto el tama√±o del √°rbol como la
magnitud de sus valores terminales, favoreciendo modelos m√°s simples y
reduciendo el riesgo de sobreajuste.

Para optimizar \(\mathcal{L}\), XGBoost utiliza una aproximaci√≥n de
segundo orden mediante series de Taylor, calculando en cada paso las
derivadas primera \((g_i\))\$ y segunda \((h_i)\) de la p√©rdida respecto
a la predicci√≥n actual:

\[
g_i = \frac{\partial \ell(y_i, \hat{y}_i)}{\partial \hat{y}_i}, \quad
h_i = \frac{\partial^2 \ell(y_i, \hat{y}_i)}{\partial \hat{y}_i^2}
\]

Con estos residuos gradiente y hessiano, el algoritmo eval√∫a de manera
eficiente el beneficio de dividir cada posible nodo del √°rbol,
escogiendo la partici√≥n que maximiza la reducci√≥n de la funci√≥n objetivo
regularizada. Adem√°s, XGBoost incorpora mecanismos como shrinkage ,
muestreo de filas y columnas subsample,colsample\_bytree, y poda de
ramas con ganancia negativa, lo que mejora a√∫n m√°s la generalizaci√≥n y
la velocidad de convergencia.

En el plano de la implementaci√≥n, XGBoost est√° altamente optimizado para
aprovechar arquitecturas modernas: emplea t√©cnicas de aprendizaje por
bloques en memoria, algoritmos de b√∫squeda de cortes aproximados,
soporte para entrenamiento paralelo y procesamiento out-of-core cuando
los datos exceden la memoria RAM. Tambi√©n maneja de forma nativa valores
faltantes, aprendiendo autom√°ticamente la mejor ruta para cada registro
con ausencia de datos en una caracter√≠stica determinada.

\includegraphics{final_merge_files/figure-pdf/cell-11-output-1.png}

\includegraphics{final_merge_files/figure-pdf/cell-11-output-2.png}

\includegraphics{final_merge_files/figure-pdf/cell-11-output-3.png}

\includegraphics{final_merge_files/figure-pdf/cell-11-output-4.png}

\includegraphics{final_merge_files/figure-pdf/cell-11-output-5.png}

\hypertarget{anuxe1lisis-de-resultados-1}{%
\subsection{An√°lisis de Resultados}\label{anuxe1lisis-de-resultados-1}}

En este estudio implementamos cuatro configuraciones del modelo XGBoost
para predecir la duraci√≥n de partidos de tenis.\\
- XGB Modelo 1: variables estructurales del torneo (7
caracter√≠sticas).\\
- XGB Modelo 2: agrega datos de performance individual (11
caracter√≠sticas).\\
- XGB Modelo 3: incorpora la duraci√≥n promedio hist√≥rica por jugador (9
caracter√≠sticas).\\
- XGB Modelo 4: combina todas las variables disponibles (14
caracter√≠sticas).

A medida que a√±adimos informaci√≥n, se observa una mejora gradual en MAE
y R¬≤ de prueba, aunque persiste un marcado sobreajuste en entrenamiento
versus prueba

\begin{longtable}[]{@{}lllllll@{}}
\toprule\noalign{}
& R2\_train & R2\_test & RMSE\_train & RMSE\_test & MAE\_train &
MAE\_test \\
Modelo & & & & & & \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Modelo 1 & 0.0477 & 0.0377 & 45.20 & 45.21 & 36.62 & 36.59 \\
Modelo 2 & 0.0506 & 0.0419 & 45.13 & 45.11 & 36.54 & 36.53 \\
Modelo 3 & 0.0613 & 0.0518 & 44.88 & 44.88 & 36.37 & 36.25 \\
Modelo 4 & 0.0644 & 0.0550 & 44.80 & 44.80 & 36.28 & 36.19 \\
\end{longtable}

\hypertarget{interpretaciuxf3n}{%
\paragraph{Interpretaci√≥n}\label{interpretaciuxf3n}}

Aunque el MAE de prueba mejora ligeramente (de 37.05 min en el Modelo 1
a 36.71 min en el Modelo 4), la capacidad predictiva en prueba sigue
siendo reducida, con \(R^2\) muy bajos (0.0121--0.0289). Se detecta un
sobreajuste significativo: la brecha entre entrenamiento y prueba
alcanza hasta 0.3688 en el Modelo 4, lo que indica que el ensamble
captura patrones espec√≠ficos del set de entrenamiento sin generalizar
adecuadamente.

En todos los modelos, los puntos de ranking del perdedor son el factor
m√°s relevante, sugiriendo que la competitividad del oponente influye de
forma consistente en la duraci√≥n de los partidos. La inclusi√≥n de la
duraci√≥n hist√≥rica promedio (w\_avg\_minutes) aporta un valor moderado
en el modelo completo, pero sigue sin resolver el bajo poder predictivo
global. Estos resultados invitan a explorar variables adicionales, como
condiciones clim√°ticas o estilos de juego y a probar enfoques h√≠bridos o
de ingenier√≠a de caracter√≠sticas para mejorar la robustez del
pron√≥stico.

\hypertarget{glm-gamma}{%
\section{GLM Gamma}\label{glm-gamma}}

\hypertarget{marco-teuxf3rico-2}{%
\subsection{Marco Te√≥rico}\label{marco-teuxf3rico-2}}

Los Modelos Lineales Generalizados (GLM) extienden la regresi√≥n lineal
cl√°sica para acomodar variables de respuesta que no siguen una
distribuci√≥n normal. Dentro de este marco, la regresi√≥n Gamma resulta
especialmente adecuada cuando la variable dependiente es continua,
estrictamente positiva y presenta asimetr√≠a derecha con varianza
creciente conforme aumenta la media.

En un GLM Gamma, se asume que cada observaci√≥n \(Y_i\) sigue una
distribuci√≥n Gamma con funci√≥n de densidad

\[
f(y_i;\,\mu_i,\phi) \;=\; \frac{1}{\Gamma(1/\phi)}\Bigl(\frac{1}{\phi \mu_i}\Bigr)^{1/\phi} y_i^{1/\phi -1} \exp\!\Bigl(-\frac{y_i}{\phi \mu_i}\Bigr),
\]

donde \(\mu_i = E[Y_i]\) es la media y \(\phi\) el par√°metro de
dispersi√≥n. La relaci√≥n media-varianza caracter√≠stica es

\[
\operatorname{Var}(Y_i) = \phi\,\mu_i^2,
\]

lo cual refleja heterocedasticidad proporcional al cuadrado de la media.

Se elige t√≠picamente la funci√≥n de enlace logar√≠tmica como v√≠nculo
can√≥nico, de modo que

\[
g(\mu_i) = \log(\mu_i) = \beta_0 + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}.
\]

Esto garantiza predicciones positivas y permite interpretar cada
coeficiente \(\beta_j\) como el cambio logar√≠tmico en la media al
incrementar en una unidad la covariable \(x_{ij}\), es decir, un efecto
multiplicativo \(\exp(\beta_j)\) sobre \(\mu_i\).

La estimaci√≥n de los par√°metros \(\boldsymbol{\beta}\) y \(\phi\) se
realiza mediante m√°xima verosimilitud, optimizando la log-verosimilitud
del modelo. El ajuste se eval√∫a a trav√©s de la desviance y criterios de
informaci√≥n como AIC y BIC, adem√°s de pseudo-\(R^2\) para medir bondad
de ajuste relativa.

En comparaci√≥n con la regresi√≥n lineal, el GLM Gamma maneja de forma
nativa la distribuci√≥n sesgada y la heterocedasticidad creciente,
mejorando la validez estad√≠stica cuando los supuestos de
homocedasticidad y normalidad no se cumplen. Por ello, resulta apropiado
para modelar tiempos de duraci√≥n u otras magnitudes positivas donde la
variabilidad se incrementa con el nivel promedio observado.

\includegraphics{final_merge_files/figure-pdf/cell-14-output-1.png}

\includegraphics{final_merge_files/figure-pdf/cell-14-output-2.png}

\includegraphics{final_merge_files/figure-pdf/cell-14-output-3.png}

\includegraphics{final_merge_files/figure-pdf/cell-14-output-4.png}

\includegraphics{final_merge_files/figure-pdf/cell-14-output-5.png}

\hypertarget{anuxe1lisis-de-resultados-2}{%
\subsection{An√°lisis de Resultados}\label{anuxe1lisis-de-resultados-2}}

En este estudio implementamos cuatro configuraciones del GLM Gamma para
modelar la duraci√≥n de partidos de tenis:

\begin{itemize}
\tightlist
\item
  GLM Modelo 1: variables estructurales del torneo y puntos de ranking
  (7 caracter√≠sticas).\\
\item
  GLM Modelo 2: a√±ade promedios de aces y dobles faltas (11
  caracter√≠sticas).\\
\item
  GLM Modelo 3: incorpora duraci√≥n promedio hist√≥rica por jugador (9
  caracter√≠sticas).\\
\item
  GLM Modelo 4: combina todas las variables disponibles, incluyendo edad
  y m√©tricas de servicio e hist√≥ricos (14 caracter√≠sticas).
\end{itemize}

A lo largo de las cuatro configuraciones se observa una mejora
progresiva en pseudo-\(R^2\) y ligeras reducciones en RMSE, MAE y en los
criterios de informaci√≥n (AIC, BIC), manteniendo un bajo grado de
sobreajuste (gap \textless{} 0.02).

\hypertarget{interpretaciuxf3n-1}{%
\subsubsection{Interpretaci√≥n}\label{interpretaciuxf3n-1}}

El ajuste del GLM Gamma mejora de forma gradual conforme incorporamos
nuevas covariables: el pseudo-\(R^2\) crece de 4.2 \% en el modelo
b√°sico a 5.7 \% en el modelo completo, mientras que el RMSE de prueba
disminuye de 45.41 a 44.98 minutos y el MAE de 36.70 a 36.30 minutos.
Los criterios de informaci√≥n AIC y BIC se reducen de 89 885.97/‚àí76
894.00 a 89 760.40/‚àí76 845.04, reflejando un mejor equilibrio entre
ajuste y complejidad, y la brecha entre R¬≤ de entrenamiento y prueba
permanece por debajo de 0.02, lo que indica un bajo nivel de
sobreajuste.

Los determinantes m√°s influyentes se mantienen constantes: un mayor
puntaje del perdedor est√° asociado con un incremento en la duraci√≥n del
partido, mientras que un mayor puntaje del ganador tiende a acortarlo.
La superficie de c√©sped ejerce un efecto claro de reducci√≥n temporal,
acortando los encuentros. Adem√°s, la inclusi√≥n de la duraci√≥n hist√≥rica
promedio de cada jugador incrementa la capacidad explicativa, cada
minuto hist√≥rico extra alarga ligeramente el partido, y las m√©tricas de
servicio (aces y dobles faltas) aportan efectos menores pero
consistentes: m√°s aces del perdedor extienden la duraci√≥n y m√°s aces del
ganador la reducen.

A pesar de estas mejoras, la variabilidad no explicada sigue superando
el 94 \%, lo que sugiere que factores externos (condiciones clim√°ticas,
estilos de juego, imponderables) podr√≠an ser clave para perfeccionar el
pron√≥stico. Para avanzar, convendr√≠a explorar interacciones,
transformaciones no lineales o variables adicionales que capturen la
complejidad inherente a la duraci√≥n de los partidos.

\hypertarget{conclusiuxf3n}{%
\section{Conclusi√≥n}\label{conclusiuxf3n}}

El recorrido metodol√≥gico de este proyecto, que incluy√≥ desde la
regresi√≥n lineal m√∫ltiple y el GLM Gamma hasta t√©cnicas de ensamble como
XGBoost y Random Forest, revela que, pese a las distintas arquitecturas
y complejidades, la capacidad predictiva sobre la duraci√≥n de partidos
de tenis se mantiene modesta. Los modelos m√°s sencillos (la regresi√≥n
lineal y el GLM Gamma) alcanzaron un \(R^2\) de prueba en torno al 5 \%
y un MAE cercano a 36.2 minutos, mientras que los enfoques basados en
√°rboles mejorados (Random Forest y XGBoost) no superaron
significativamente este umbral y presentaron un sobreajuste mucho m√°s
marcado, con brechas de hasta 0.66 entre entrenamiento y prueba.

La similitud en RMSE (aproximadamente 44.8--45.8 minutos) y MAE
(36.2--37.1 minutos) entre todas las t√©cnicas sugiere que las variables
usadas para el modelado; puntos de ranking, superficie de juego,
estad√≠sticas de servicio y promedios hist√≥ricos; explican solo una
fracci√≥n limitada de la variabilidad real. En particular, la inclusi√≥n
de minutos hist√≥ricos y m√©tricas de aces aporta mejoras marginales, pero
no revierte la baja potencia predictiva global. La eliminaci√≥n de
covariables con alta multicolinealidad mediante el an√°lisis de VIF ayud√≥
a estabilizar los coeficientes y facilitar la interpretaci√≥n, pero no
cambi√≥ sustancialmente los resultados.

En conjunto, estos hallazgos indican que la duraci√≥n de un partido de
tenis est√° determinada por factores adicionales no capturados aqu√≠, como
condiciones clim√°ticas, estilos de juego individuales, cambios t√°cticos
en el partido o din√°micas psicol√≥gicas y que, para elevar la precisi√≥n,
ser√° necesario incorporar nuevas fuentes de informaci√≥n y explorar
interacciones o transformaciones no lineales. Dado el equilibrio entre
interpretabilidad y robustez, los modelos lineales y el GLM Gamma
constituyen un punto de partida s√≥lido, mientras que los m√©todos de
ensamble podr√≠an reservarse para entornos con mayor cantidad de datos o
variables m√°s ricas. Este estudio sienta las bases para futuras
iteraciones centradas en enriquecer el conjunto de caracter√≠sticas y en
dise√±ar estrategias de modelado h√≠brido capaces de capturar la compleja
din√°mica de la duraci√≥n de los encuentros.

\hypertarget{referencias}{%
\section{Referencias}\label{referencias}}

\begin{itemize}
\item
  Battagliola, M. L. (2025). Estadistica Aplicada 2. Instituto
  Tecnol√≥gico Aut√≥nomo de M√©xico.
\item
  Hardin, J. W., \& Hilbe, J. M. (2018). Generalized Linear Models and
  Extensions (4th ed.). CRC Press.
\item
  Tianqi Chen and Carlos Guestrin. 2016. XGBoost: A Scalable Tree
  Boosting System. In Proceedings of the 22nd ACM SIGKDD International
  Conference on Knowledge Discovery and Data Mining (KDD '16).
  Association for Computing Machinery, New York, NY, USA, 785--794.
  doi.org/10.1145/2939672.2939785
\end{itemize}



\end{document}
